{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is used to analyze and generate a rendering for the first 4 scores of Ludus Musicalis by Roman Haubenstock-Ramati.\n",
    "\n",
    "The scores physical size is ~20x20 cm (?) (square aspect ratio).\n",
    "\n",
    "They can be read from 4 different directions, and can be performed simultaneously or in sequence.\n",
    "\n",
    "The companion document explain the meaning of the symbols and how the pieces should be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiling instructions\n",
    "# pip install line_profiler\n",
    "# %%prun -s cumulative\n",
    "\n",
    "# pip install memory_profiler\n",
    "#%load_ext memory_profiler\n",
    "#%reload_ext memory_profiler\n",
    "#%mprun\n",
    "\n",
    "#%%memit -r 1\n",
    "# Profile a cell by running it _once_\n",
    "# %%memit MUST be the first line in a cell, even before comments..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# First import the MTM package and check its version: \n",
    "# pip install multi-template-matching\n",
    "# Should be 2.0.1 as 2.0.0 had a bug\n",
    "# It fails if you already have OpenCV (remove it first)\n",
    "import MTM\n",
    "from MTM import drawBoxesOnRGB, matchTemplates\n",
    "print(\"MTM version: \", MTM.__version__)\n",
    "\n",
    "import os\n",
    "import platform\n",
    "\n",
    "# For parallelizing long computations (where possible)\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "\n",
    "# But we need OpenCV anyway for image processing so we must reinstall it after: \n",
    "# pip install opencv-python\n",
    "import cv2\n",
    "from scipy.ndimage import rotate\n",
    "import numpy as np\n",
    "# pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage as ski\n",
    "\n",
    "# For the gamma curve\n",
    "# pip install splines\n",
    "import splines\n",
    "\n",
    "# PyWebView is used for dialog boxes: \n",
    "# pip install pywebview\n",
    "import webview\n",
    "\n",
    "# mido is used to generate midi files and messages\n",
    "# On Win: pip install mido[ports-rtmidi]\n",
    "# On Mac: pip install python-rtmidi \n",
    "#         pip install mido\n",
    "from mido import MetaMessage, Message, MidiFile, MidiTrack\n",
    "\n",
    "# For creating scores\n",
    "# pip install music21\n",
    "import music21\n",
    "# Music 21 does not recognize MuseScore 4 yet, set the correct location\n",
    "# On Windows:\n",
    "# music21.environment.set('musescoreDirectPNGPath', 'C:\\\\Program Files\\\\MuseScore 4\\\\bin\\\\MuseScore4.exe')\n",
    "# On Mac:\n",
    "# TODO\n",
    "\n",
    "# With PyWebView we prepare the file dialog to show only the supported image types.\n",
    "def webview_file_dialog():\n",
    "    file = None\n",
    "    file_types = ('Image Files (*.bmp;*.jpg;*.gif)', 'All files (*.*)')\n",
    "    def open_file_dialog(w):\n",
    "        nonlocal file\n",
    "        try:\n",
    "            file = w.create_file_dialog(webview.OPEN_DIALOG, allow_multiple=False, file_types=file_types)[0]\n",
    "        except TypeError:\n",
    "            pass  # User exited file dialog without picking\n",
    "        finally:\n",
    "            w.destroy()\n",
    "    window = webview.create_window(\"\", hidden=True)\n",
    "    webview.start(open_file_dialog, window)\n",
    "    # file will either be a string or None\n",
    "    return file\n",
    "\n",
    "# Custom image scaling function\n",
    "def scale_image(image, percent, maxwh):\n",
    "    max_width = maxwh[1]\n",
    "    max_height = maxwh[0]\n",
    "    max_percent_width = max_width / image.shape[1] * 100\n",
    "    max_percent_height = max_height / image.shape[0] * 100\n",
    "    max_percent = 0\n",
    "    if max_percent_width < max_percent_height:\n",
    "        max_percent = max_percent_width\n",
    "    else:\n",
    "        max_percent = max_percent_height\n",
    "    if percent > max_percent:\n",
    "        percent = max_percent\n",
    "    width = int(image.shape[1] * percent / 100)\n",
    "    height = int(image.shape[0] * percent / 100)\n",
    "    result = cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    return result, percent\n",
    "\n",
    "# Get dimensions of a window. We are working with fullscreen windows on the main display to simplify the process.\n",
    "def get_screen_dimensions(window_name=\"Gamma Correction Preview\"):\n",
    "    import platform\n",
    "    import cv2\n",
    "    if platform.system() != \"Darwin\":\n",
    "        # Get the dimensions of the specified window.\n",
    "        (_, _, screen_width, screen_height) = cv2.getWindowImageRect(window_name)\n",
    "    else:\n",
    "        # On macOS, use AppKit instead.\n",
    "        import AppKit\n",
    "        main_screen = AppKit.NSScreen.mainScreen()\n",
    "        frame = main_screen.frame()\n",
    "        screen_width = int(frame.size.width)\n",
    "        screen_height = int(frame.size.height)\n",
    "    return screen_width, screen_height\n",
    "\n",
    "# Compute the LUT using a spline defined only on [low_val, high_val]\n",
    "# The mapping is: low_val -> 0, mid -> 128, high_val -> 255.\n",
    "def create_custom_LUT(low, mid_pt, high):\n",
    "    LUT = np.zeros(256, dtype=np.uint8)\n",
    "    # Compute the spline for x between low and high.\n",
    "    spline = splines.CatmullRom([0, 128, 255], [low, mid_pt, high])\n",
    "    x_range = np.arange(low, high + 1)\n",
    "    LUT[low:high + 1] = np.clip(spline.evaluate(x_range), 0, 255).astype(np.uint8)\n",
    "    LUT[:low] = 0\n",
    "    LUT[high + 1:] = 255\n",
    "    return LUT\n",
    "\n",
    "# Function to create a custom LUT for gamma correction.\n",
    "def interactive_gamma_correction(musicSearch):\n",
    "    \"\"\"\n",
    "    Opens a fullscreen interactive window that lets the user adjust the gamma\n",
    "    correction using independent controls for the midpoint and the spread.\n",
    "    \n",
    "    Controls:\n",
    "      W/S: Increase/decrease the midpoint.\n",
    "      Q/A: Decrease/increase the spread (i.e. tighten or widen the mapping range).\n",
    "      T: Toggle gamma correction on/off.\n",
    "      ENTER/SPACE: Confirm selection.\n",
    "      \n",
    "    When gamma correction is toggled off, the preview displays the original image.\n",
    "    \n",
    "    Returns:\n",
    "       The processed image: if gamma correction is active, the gamma-corrected image,\n",
    "       otherwise the original image.\n",
    "    \"\"\"\n",
    "    # Define parameters for the controls.\n",
    "    mid = 127             # Starting midpoint value.\n",
    "    spread = 127           # Starting half-range so that low = 0, high = 254.\n",
    "    delta_mid = 1         # Adjustment step for midpoint.\n",
    "    delta_spread = 1      # Adjustment step for spread.\n",
    "    min_spread = 1        # Minimum spread value.\n",
    "    deactivated = False   # Flag to indicate gamma correction is off.\n",
    "\n",
    "    # Create fullscreen window for preview.\n",
    "    window_name = \"Gamma Correction Preview\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    cv2.startWindowThread()\n",
    "\n",
    "    # Main interactive loop.\n",
    "    while True:\n",
    "        # Compute the dependent low and high from mid and spread.\n",
    "        low_val = mid - spread\n",
    "        high_val = mid + spread\n",
    "\n",
    "        # Create the LUT only if gamma correction is active.\n",
    "        if not deactivated:\n",
    "            def create_custom_LUT(low, mid_pt, high):\n",
    "                LUT = np.zeros(256, dtype=np.uint8)\n",
    "                spline = splines.CatmullRom([0, 128, 255], [low, mid_pt, high])\n",
    "                x_range = np.arange(low, high + 1)\n",
    "                LUT[low:high + 1] = np.clip(spline.evaluate(x_range), 0, 255).astype(np.uint8)\n",
    "                LUT[:low] = 0\n",
    "                LUT[high + 1:] = 255\n",
    "                return LUT\n",
    "            LUT = create_custom_LUT(low_val, mid, high_val)\n",
    "        \n",
    "        screen_width, screen_height = get_screen_dimensions(window_name)\n",
    "        # Build curve points by mapping the LUT if active.\n",
    "        pts = []\n",
    "        if not deactivated:\n",
    "            for i in range(256):\n",
    "                x = int(i / 255 * (screen_width - 1))\n",
    "                y = int(screen_height - 1 - (LUT[i] / 255.0 * (screen_height - 1)))\n",
    "                pts.append((x, y))\n",
    "            pts = np.array(pts, np.int32).reshape((-1, 1, 2))\n",
    "        \n",
    "        # Create preview.\n",
    "        if deactivated:\n",
    "            preview = musicSearch.copy()\n",
    "        else:\n",
    "            preview = cv2.LUT(musicSearch, LUT)\n",
    "\n",
    "        # Build overlay text.\n",
    "        if deactivated:\n",
    "            overlay_text = (\"Gamma Correction DISABLED    \"\n",
    "                            \"[T: enable correction]    [ENTER/SPACE: confirm]\")\n",
    "        else:\n",
    "            overlay_text = (f\"Mid: {mid}, Spread: {spread}, Low: {low_val}, High: {high_val}    \"\n",
    "                            \"[W/S: move mid]    [Q: tighten, A: widen]    \"\n",
    "                            \"[T: disable correction]    [ENTER/SPACE: confirm]\")\n",
    "        \n",
    "        cv2.putText(preview, overlay_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Draw the curve if gamma correction is active.\n",
    "        if not deactivated:\n",
    "            cv2.polylines(preview, [pts], isClosed=False, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # Show preview.\n",
    "        cv2.imshow(window_name, preview)\n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "        # Adjust controls based on key pressed.\n",
    "        if key == ord('w'):\n",
    "            # Increase the midpoint, ensuring mid + spread <= 255.\n",
    "            mid = min(mid + delta_mid, 255 - spread)\n",
    "        elif key == ord('s'):\n",
    "            # Decrease the midpoint, ensuring mid - spread >= 0.\n",
    "            mid = max(mid - delta_mid, spread)\n",
    "        elif key == ord('q'):\n",
    "            # Tighten: reduce spread if possible.\n",
    "            spread = max(min_spread, spread - delta_spread)\n",
    "        elif key == ord('a'):\n",
    "            # Widen: increase spread ensuring bounds.\n",
    "            spread = min(spread + delta_spread, min(mid, 255 - mid))\n",
    "        elif key == ord('t'):\n",
    "            # Toggle gamma correction.\n",
    "            deactivated = not deactivated\n",
    "        elif key in [13, 32]:\n",
    "            # Confirm selection.\n",
    "            break\n",
    "\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    # Return the final image: if deactivated, original; else, apply final LUT.\n",
    "    if deactivated:\n",
    "        return musicSearch\n",
    "    else:\n",
    "        return cv2.LUT(musicSearch, LUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the user with the choice of analyzing one of the first 4 scores, supplying another image, or acquiring an image with a webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "valid_scores = {1, 2, 3, 4, 5, 6}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter the score number that you want to analyze (1-2 Punkte, 3-4 Pizzicati, 5 Other files, 6 Camera) [type 'q' to quit]: \")\n",
    "    if user_input.lower() in [\"q\", \"quit\"]:\n",
    "        raise SystemExit(\"User requested exit.\")\n",
    "\n",
    "    try:\n",
    "        scoreNumber = int(user_input)\n",
    "        if scoreNumber in valid_scores:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid score number. Please enter a number between 1 and 6.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a valid integer or 'q' to exit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# If you have multiple webcams connected you need to determine which one to use\n",
    "# pip install cv2_enumerate_cameras\n",
    "from cv2_enumerate_cameras import enumerate_cameras\n",
    "#Set search files and bounding boxes\n",
    "filenameSearch=''\n",
    "filenameTemplates=''\n",
    "\n",
    "match scoreNumber:\n",
    "    #Punkte\n",
    "    case 1:\n",
    "        filenameTemplates = './input/LudusMusicalis1DPI300Gamma.jpg'\n",
    "        filenameSearch='./input/LudusMusicalis1DPI300Gamma.jpg'\n",
    "        searchBoxX=250\n",
    "        searchBoxY=305\n",
    "        searchBoxWidth=1990\n",
    "        searchBoxHeight=2030\n",
    "        ruleSet=1\n",
    "    case 2:\n",
    "        filenameTemplates = './input/LudusMusicalis1DPI300Gamma.jpg'\n",
    "        filenameSearch='./input/LudusMusicalis2DPI300Gamma.jpg'\n",
    "        searchBoxX=250\n",
    "        searchBoxY=290\n",
    "        searchBoxWidth=2000\n",
    "        searchBoxHeight=2030\n",
    "        ruleSet=1\n",
    "    # Pizzicati\n",
    "    case 3:\n",
    "        filenameTemplates = './input/LudusMusicalis3DPI300Gamma.jpg'\n",
    "        filenameSearch='./input/LudusMusicalis3DPI300Gamma.jpg'\n",
    "        searchBoxX=240\n",
    "        searchBoxY=280\n",
    "        searchBoxWidth=2000\n",
    "        searchBoxHeight=2050\n",
    "        ruleSet=2\n",
    "    case 4:\n",
    "        filenameTemplates = './input/LudusMusicalis3DPI300Gamma.jpg'\n",
    "        filenameSearch='./input/LudusMusicalis4DPI300Gamma.jpg'\n",
    "        searchBoxX=250\n",
    "        searchBoxY=280\n",
    "        searchBoxWidth=2000\n",
    "        searchBoxHeight=2050\n",
    "        ruleSet=2\n",
    "    case 5:\n",
    "        filenameSearch=webview_file_dialog()\n",
    "        if filenameSearch==None:\n",
    "            raise SystemExit(\"No File Selected\")\n",
    "        \n",
    "        valid_rule_sets = {1, 2}\n",
    "        while True:\n",
    "            ruleSet_input = input(\"Enter the set of rules you want to adopt (1 Punkte, 2 Pizzicati) [type 'q' to quit]: \")\n",
    "            if ruleSet_input.lower() in ['q', 'quit']:\n",
    "                raise SystemExit(\"User requested exit.\")\n",
    "            try:\n",
    "                ruleSet = int(ruleSet_input)\n",
    "                if ruleSet in valid_rule_sets:\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid rule set. Please enter 1 for Punkte or 2 for Pizzicati.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a numeric value or 'q' to exit.\")\n",
    "\n",
    "        if ruleSet==2:\n",
    "            filenameTemplates = './input/LudusMusicalis3DPI300Gamma.jpg'\n",
    "        elif ruleSet==1:\n",
    "            filenameTemplates = './input/LudusMusicalis1DPI300Gamma.jpg'\n",
    "        else :\n",
    "            raise SystemExit(\"Invalid Input\")\n",
    "        # ScanNewPizzicati.jpg coordinates\n",
    "        searchBoxX=350\n",
    "        searchBoxY=100\n",
    "        searchBoxWidth=2300\n",
    "        searchBoxHeight=2290\n",
    "\n",
    "    case 6:\n",
    "        print(\"Opening camera\")\n",
    "\n",
    "    case _:\n",
    "        # Anything else.\n",
    "        # \n",
    "        # If `case _:` is omitted, an error will be thrown\n",
    "        # if `something` doesn't match any of the patterns.\n",
    "        raise SystemExit(\"Invalid Input\")\n",
    "\n",
    "if scoreNumber==6:\n",
    "        \n",
    "        # On Mac this package has no implementation yet...\n",
    "        if platform.system() != \"Darwin\":\n",
    "            for camera_info in enumerate_cameras(cv2.CAP_MSMF):\n",
    "                print(f'{camera_info.index}: {camera_info.name}')\n",
    "        else:\n",
    "            print(\"Camera enumeration is not supported on Mac.\")\n",
    "\n",
    "        # You might want to manually set the focus of the camera, in this case you need the appropriate drivers, and making sure that multiple applications can access the camera at the same time.\n",
    "\n",
    "        # If you pass unreasonably high values for the resolution the camera will return the highest available.\n",
    "        HIGH_VALUE = 100000\n",
    "        WIDTH = HIGH_VALUE\n",
    "        HEIGHT = HIGH_VALUE\n",
    "        # Some cameras, such as the Logitech C920, do not report their correct resolution. This particular camera is 1920x1080, but it reports 2560x1472.\n",
    "        # The only solution is to manually set the correct values.\n",
    "        # WIDTH = 1920\n",
    "        # HEIGHT = 1080\n",
    "\n",
    "        while True:\n",
    "                cam_choice = input(\"Enter the webcam index you want to use [type 'q' to quit]: \")\n",
    "                if cam_choice.lower() in [\"q\", \"quit\"]:\n",
    "                    raise SystemExit(\"User requested exit.\")\n",
    "                try:\n",
    "                    cam_choice = int(cam_choice)\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    print(\"Invalid input. Please enter a numeric value.\")\n",
    "\n",
    "        # Open the camera\n",
    "        capture = cv2.VideoCapture(cam_choice,cv2.CAP_ANY)\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        #fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "        capture.set(cv2.CAP_PROP_FOURCC, fourcc)\n",
    "\n",
    "        # Similarly to resolution a high value is replaced with the actual maximum for FPS.\n",
    "        capture.set(cv2.CAP_PROP_FPS, 120)\n",
    "        cfps = int(capture.get(cv2.CAP_PROP_FPS))\n",
    "        print(f\"Camera FPS: {cfps}\")\n",
    "        print(f\"Camera Backend: {capture.getBackendName()}\")\n",
    "        print(capture.get(cv2.CAP_PROP_FOURCC))\n",
    "\n",
    "\n",
    "\n",
    "        capture.set(cv2.CAP_PROP_FRAME_WIDTH, WIDTH)\n",
    "        capture.set(cv2.CAP_PROP_FRAME_HEIGHT, HEIGHT)\n",
    "        width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        print(f\"Camera resolution: {width}x{height}\")\n",
    "\n",
    "        cv2.namedWindow(\"Acquire an image\", cv2.WND_PROP_FULLSCREEN)\n",
    "        cv2.setWindowProperty(\"Acquire an image\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "        # On Mac this seems to be needed\n",
    "        cv2.startWindowThread()\n",
    "\n",
    "        # Get screen size\n",
    "        screen_width, screen_height = get_screen_dimensions(\"Acquire an image\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = capture.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                break\n",
    "        \n",
    "            \n",
    "            # Maintain aspect ratio while fitting to screen\n",
    "            aspect_ratio = width / height\n",
    "            if screen_width / screen_height > aspect_ratio:\n",
    "                new_height = screen_height\n",
    "                new_width = int(screen_height * aspect_ratio)\n",
    "            else:\n",
    "                new_width = screen_width\n",
    "                new_height = int(screen_width / aspect_ratio)\n",
    "            \n",
    "            resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "            \n",
    "            # Create a black canvas and center the resized frame on it\n",
    "            canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "            y_offset = (screen_height - new_height) // 2\n",
    "            x_offset = (screen_width - new_width) // 2\n",
    "            canvas[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = resized_frame\n",
    "            \n",
    "            # Determine the smallest dimension for squares\n",
    "            min_dim = min(new_width, new_height)\n",
    "            \n",
    "            # Calculate larger green square properties\n",
    "            large_square_size = int(0.9 * min_dim)\n",
    "            large_x1 = (screen_width - large_square_size) // 2\n",
    "            large_y1 = (screen_height - large_square_size) // 2\n",
    "            large_x2 = large_x1 + large_square_size\n",
    "            large_y2 = large_y1 + large_square_size\n",
    "            \n",
    "            # Calculate smaller green square properties\n",
    "            small_square_size = int(0.7 * min_dim)\n",
    "            small_x1 = (screen_width - small_square_size) // 2\n",
    "            small_y1 = (screen_height - small_square_size) // 2\n",
    "            small_x2 = small_x1 + small_square_size\n",
    "            small_y2 = small_y1 + small_square_size\n",
    "            \n",
    "            # Draw green squares\n",
    "            color = (0, 255, 0)  # Green color in BGR\n",
    "            thickness = 1  # Thickness of the square\n",
    "            \n",
    "            # Draw the larger square\n",
    "            cv2.rectangle(canvas, (large_x1, large_y1), (large_x2, large_y2), color, thickness)\n",
    "            # Draw the smaller square\n",
    "            cv2.rectangle(canvas, (small_x1, small_y1), (small_x2, small_y2), color, thickness)\n",
    "            \n",
    "            cv2.imshow(\"Acquire an image\", canvas)\n",
    "            \n",
    "            k = cv2.waitKey(1)\n",
    "            if k % 256 == 27:\n",
    "                # ESC pressed\n",
    "                print(\"Escape hit, closing...\")\n",
    "                break\n",
    "            elif k % 256 == 32:\n",
    "                # SPACE pressed\n",
    "                print(\"Image acquired.\")\n",
    "                musicSearch = frame\n",
    "\n",
    "        capture.release()\n",
    "        # Workaround for Mac...\n",
    "        cv2.waitKey(1)\n",
    "        cv2.destroyAllWindows()\n",
    "        # The creation of two consecutive fullscreen windows seems to be problematic on Mac. Adding a conservative delay between the two windows seems to fix the issue.\n",
    "        cv2.waitKey(1000)\n",
    "        #cv2.destroyWindow(\"Acquire an image\")\n",
    "\n",
    "        # Function to apply Gamma correction\n",
    "        musicSearch = interactive_gamma_correction(musicSearch)\n",
    "\n",
    "        musicVisualize = musicSearch.copy()\n",
    "\n",
    "        valid_rule_sets = {1, 2}\n",
    "        while True:\n",
    "            ruleSet_input = input(\"Enter the set of rules you want to adopt (1 Punkte, 2 Pizzicati) [type 'q' to quit]: \")\n",
    "            if ruleSet_input.lower() in ['q', 'quit']:\n",
    "                raise SystemExit(\"User requested exit.\")\n",
    "            try:\n",
    "                ruleSet = int(ruleSet_input)\n",
    "                if ruleSet in valid_rule_sets:\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Invalid rule set. Please enter 1 for Punkte or 2 for Pizzicati.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a valid integer or 'q' to exit.\")\n",
    "\n",
    "        if ruleSet==2:\n",
    "            filenameTemplates = './input/LudusMusicalis3DPI300Gamma.jpg'\n",
    "        elif ruleSet==1:\n",
    "            filenameTemplates = './input/LudusMusicalis1DPI300Gamma.jpg'\n",
    "        else :\n",
    "            raise SystemExit(\"Invalid Input\")\n",
    "        # ScanNewPizzicati.jpg coordinates\n",
    "        searchBoxX=350\n",
    "        searchBoxY=100\n",
    "        searchBoxWidth=2300\n",
    "        searchBoxHeight=2290\n",
    "\n",
    "if os.path.exists(filenameTemplates):\n",
    "    musicTemplate = (ski.io.imread(filenameTemplates, as_gray=True)* 255).astype(np.uint8)\n",
    "else:\n",
    "    # Create an empty image with default dimensions (e.g., 2500x2500 pixels, 1 channel)\n",
    "    musicTemplate = np.zeros((2500, 2500, 1), dtype=np.uint8)\n",
    "musicVisualizeTemplate=musicTemplate.copy()\n",
    "\n",
    "if scoreNumber != 6:\n",
    "    if os.path.exists(filenameSearch):\n",
    "        musicSearch = (ski.io.imread(filenameSearch, as_gray=True)* 255).astype(np.uint8)\n",
    "        musicVisualize = musicSearch.copy()\n",
    "    else:\n",
    "        print(f\"Error: The search file '{filenameSearch}' was not found.\")\n",
    "        raise SystemExit(\"Application stopped because the required search file is missing.\")\n",
    "\n",
    "if (scoreNumber==5 or scoreNumber==6):\n",
    "    # With that we can select a Region of Interest. Press Enter or Space to confirm the selection.\n",
    "    # Performance on Mac is pretty bad for drawing/interacting, but works fine after that.\n",
    "    cv2.namedWindow(\"Select Bounding Box\", cv2.WND_PROP_FULLSCREEN)\n",
    "    cv2.setWindowProperty(\"Select Bounding Box\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "    cv2.startWindowThread()\n",
    "\n",
    "    # Call selectROI on the fullscreen window\n",
    "    ROI = cv2.selectROI(\"Select Bounding Box\", cv2.cvtColor(musicVisualize, cv2.COLOR_BGR2RGB), showCrosshair=True, printNotice=True)\n",
    "    searchBoxX=ROI[0]\n",
    "    searchBoxY=ROI[1]\n",
    "    searchBoxWidth=ROI[2]\n",
    "    searchBoxHeight=ROI[3]\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    if searchBoxHeight<100 or searchBoxWidth<100:\n",
    "        raise SystemExit(\"Invalid Input\")\n",
    "\n",
    "colorBox = (255, 255, 0)\n",
    "colorTemplate = (0, 255, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a list of templates used for matching the various symbols.\n",
    "\n",
    "Pizzicati contains only one symbol (a cross), but Punkte has variations in: 1 Size, 2 Empty/Full, and 3 Normal, Single Strike, Double Strike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "valid_template_sets = {1, 2}\n",
    "while True:\n",
    "    template_input = input(\"Enter the type of templates you want to use (1 Original Files, 2 Generated templates) [type 'q' to quit]: \")\n",
    "    if template_input.lower() in ['q', 'quit']:\n",
    "        raise SystemExit(\"User requested exit.\")\n",
    "    try:\n",
    "        templateSet = int(template_input)\n",
    "        if templateSet in valid_template_sets:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid template type. Please enter 1 for Original Files or 2 for Generated templates.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a valid integer or 'q' to exit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# Build Templates\n",
    "match ruleSet:\n",
    "    #Punkte\n",
    "    case 1:\n",
    "        match templateSet:\n",
    "            case 1:\n",
    "                # Original Templates\n",
    "                partDot = musicTemplate[2360:2360+82, 1214:1214+80]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (1214, 2360), (1214+80, 2360+82), colorTemplate, 1)\n",
    "                bigWhiteDot = musicTemplate[675:675+38, 1352:1352+34]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (1352, 675), (1352+34, 675+38), colorTemplate, 1)\n",
    "                mediumWhiteDot = musicTemplate[684:684+26, 1440:1440+24]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (1440, 684), (1440+24, 684+26), colorTemplate, 1)\n",
    "                smallWhiteDot = musicTemplate[782:782+21, 1438:1438+16]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (1438, 782), (1438+16, 782+21), colorTemplate, 1)\n",
    "                bigBlackDot = musicTemplate[752:752+38, 964:964+34]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (964, 752), (964+34,752+38), colorTemplate, 1)\n",
    "                mediumBlackDot = musicTemplate[813:813+27, 960:960+26]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (960, 813), (960+26, 813+27), colorTemplate, 1)\n",
    "                smallBlackDot = musicTemplate[824:824+22, 1008:1008+20]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (1008, 824), (1008+20, 824+22), colorTemplate, 1)\n",
    "                mediumWhiteDoubleStrikeDot = musicTemplate[1361:1361+40, 1874:1874+43]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (1874, 1361), (1874+43, 1361+40), colorTemplate, 1)\n",
    "                #mediumWhiteDoubleStrikeDot = music[1369:1369+26, 1884:1884+24]\n",
    "                mediumWhiteSingleStrikeDot = musicTemplate[993:993+28, 348:348+34]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (348, 993), (348+34, 993+28), colorTemplate, 1)\n",
    "                mediumBlackDoubleStrikeDot = musicTemplate[1162:1162+38, 381:381+45]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (381, 1162), (381+45, 1162+38), colorTemplate, 1)\n",
    "                mediumBlackSingleStrikeDot = musicTemplate[1161:1161+30, 1806:1806+45]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (1806, 1161), (1806+45, 1161+30), colorTemplate, 1)\n",
    "\n",
    "                plt.figure(0)\n",
    "                plt.title(\"Part Dot\")\n",
    "                plt.imshow(partDot, cmap=\"gray\")\n",
    "                plt.figure(1)\n",
    "                plt.title(\"Big White Dot\")\n",
    "                plt.imshow(bigWhiteDot, cmap=\"gray\")\n",
    "                plt.figure(2)\n",
    "                plt.title(\"Medium White Dot\")\n",
    "                plt.imshow(mediumWhiteDot, cmap=\"gray\")\n",
    "                plt.figure(3)\n",
    "                plt.title(\"Small White Dot\")\n",
    "                plt.imshow(smallWhiteDot, cmap=\"gray\")\n",
    "                plt.figure(4)\n",
    "                plt.title(\"Big Black Dot\")\n",
    "                plt.imshow(bigBlackDot, cmap=\"gray\")\n",
    "                plt.figure(5)\n",
    "                plt.title(\"Medium Black Dot\")\n",
    "                plt.imshow(mediumBlackDot, cmap=\"gray\")\n",
    "                plt.figure(6)\n",
    "                plt.title(\"Small Black Dot\")\n",
    "                plt.imshow(smallBlackDot, cmap=\"gray\")\n",
    "                plt.figure(7)\n",
    "                plt.title(\"Medium White Double Strike Dot\")\n",
    "                plt.imshow(mediumWhiteDoubleStrikeDot, cmap=\"gray\")\n",
    "                plt.figure(8)\n",
    "                plt.title(\"Medium White Single Strike Dot\")\n",
    "                plt.imshow(mediumWhiteSingleStrikeDot, cmap=\"gray\")\n",
    "                plt.figure(9)\n",
    "                plt.title(\"Medium Black Double Strike Dot\")\n",
    "                plt.imshow(mediumBlackDoubleStrikeDot, cmap=\"gray\")\n",
    "                plt.figure(10)\n",
    "                plt.title(\"Medium Black Single Strike Dot\")\n",
    "                plt.imshow(mediumBlackSingleStrikeDot, cmap=\"gray\")\n",
    "            case 2:\n",
    "                # Generated Templates\n",
    "                # For some reason the grayscale conversion uses 64 bit Floats. Multi Template Matching only allows 8 and 32 bit images.\n",
    "                MDTemplateGenerated = ski.io.imread('./templates/MWDTemplateGenerated.jpg', as_gray=True)\n",
    "                mediumWhiteDot = (MDTemplateGenerated * 255).astype(np.uint8)\n",
    "                MDTemplateGenerated = ski.io.imread('./templates/MBDTemplateGenerated.jpg', as_gray=True)\n",
    "                mediumBlackDot = (MDTemplateGenerated * 255).astype(np.uint8)\n",
    "                MDTemplateGenerated = ski.io.imread('./templates/WDDTemplateGenerated.jpg', as_gray=True)\n",
    "                mediumWhiteDoubleStrikeDot = (MDTemplateGenerated * 255).astype(np.uint8)\n",
    "                MDTemplateGenerated = ski.io.imread('./templates/WSDTemplateGenerated.jpg', as_gray=True)\n",
    "                mediumWhiteSingleStrikeDot = (MDTemplateGenerated * 255).astype(np.uint8)\n",
    "                MDTemplateGenerated = ski.io.imread('./templates/BDDTemplateGenerated.jpg',as_gray=True)\n",
    "                mediumBlackDoubleStrikeDot = (MDTemplateGenerated * 255).astype(np.uint8)\n",
    "                MDTemplateGenerated = ski.io.imread('./templates/BSDTemplateGenerated.jpg',as_gray=True)\n",
    "                mediumBlackSingleStrikeDot = (MDTemplateGenerated * 255).astype(np.uint8)\n",
    "\n",
    "                plt.figure(0)\n",
    "                plt.title(\"Medium White Dot\")\n",
    "                plt.imshow(mediumWhiteDot, cmap=\"gray\")\n",
    "                plt.figure(1)\n",
    "                plt.title(\"Medium Black Dot\")\n",
    "                plt.imshow(mediumBlackDot, cmap=\"gray\")\n",
    "                plt.figure(2)\n",
    "                plt.title(\"Medium White Double Strike Dot\")\n",
    "                plt.imshow(mediumWhiteDoubleStrikeDot, cmap=\"gray\")\n",
    "                plt.figure(3)\n",
    "                plt.title(\"Medium White Single Strike Dot\")\n",
    "                plt.imshow(mediumWhiteSingleStrikeDot, cmap=\"gray\")\n",
    "                plt.figure(4)\n",
    "                plt.title(\"Medium Black Double Strike Dot\")\n",
    "                plt.imshow(mediumBlackDoubleStrikeDot, cmap=\"gray\")\n",
    "                plt.figure(5)\n",
    "                plt.title(\"Medium Black Single Strike Dot\")\n",
    "                plt.imshow(mediumBlackSingleStrikeDot, cmap=\"gray\")\n",
    "            case _:\n",
    "                # Anything else.\n",
    "                # \n",
    "                # If `case _:` is omitted, an error will be thrown\n",
    "                # if `something` doesn't match any of the patterns.\n",
    "                raise SystemExit(\"Invalid Input\")\n",
    "            \n",
    "    case 2:\n",
    "        # Pizzicati\n",
    "        match templateSet:\n",
    "            case 1:\n",
    "                # Original Templates\n",
    "                partDot = musicTemplate[2348:2348+84, 1217:1217+80]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (1217, 2348), (1217+80, 2348+84), colorTemplate, 1)\n",
    "                mediumCross = musicTemplate[1207:1207+24, 1265:1265+30]\n",
    "                cv2.rectangle(musicVisualizeTemplate, (1265, 1207), (1265+30, 1207+24), colorTemplate, 1)\n",
    "\n",
    "                plt.figure(0)\n",
    "                plt.title(\"Part Dot\")\n",
    "                plt.imshow(partDot, cmap=\"gray\")\n",
    "                plt.figure(1)\n",
    "                plt.title(\"Medium Cross\")\n",
    "                plt.imshow(mediumCross, cmap=\"gray\")\n",
    "            case 2:\n",
    "                # Generated Templates\n",
    "                # For some reason the grayscale conversion uses 64 bit Floats. Multi Template Matching only allows 8 and 32 bit images.\n",
    "                MCTemplateGenerated = ski.io.imread('./templates/MCTemplateGenerated1.jpg', as_gray=True)\n",
    "                mediumCross = (MCTemplateGenerated * 255).astype(np.uint8)\n",
    "                MCTemplateGenerated = ski.io.imread('./templates/MCTemplateGenerated2.jpg', as_gray=True)\n",
    "                mediumCross2 = (MCTemplateGenerated * 255).astype(np.uint8)\n",
    "                MCTemplateGenerated = ski.io.imread('./templates/MCTemplateGenerated3.jpg', as_gray=True)\n",
    "                mediumCross3 = (MCTemplateGenerated * 255).astype(np.uint8)\n",
    "                MCTemplateGenerated = ski.io.imread('./templates/MCTemplateGenerated4.jpg', as_gray=True)\n",
    "                mediumCross4 = (MCTemplateGenerated * 255).astype(np.uint8)\n",
    "                MCTemplateGenerated = ski.io.imread('./templates/MCTemplateGenerated5.jpg', as_gray=True)\n",
    "                mediumCross5 = (MCTemplateGenerated * 255).astype(np.uint8)\n",
    "                MCTemplateGenerated = ski.io.imread('./templates/MCTemplateGenerated6.jpg', as_gray=True)\n",
    "                mediumCross6 = (MCTemplateGenerated * 255).astype(np.uint8)\n",
    "                \n",
    "                plt.figure(0)\n",
    "                plt.title(\"Medium Cross\")\n",
    "                plt.imshow(mediumCross, cmap=\"gray\")\n",
    "                plt.figure(1)\n",
    "                plt.title(\"Medium Cross\")\n",
    "                plt.imshow(mediumCross2, cmap=\"gray\")\n",
    "                plt.figure(2)\n",
    "                plt.title(\"Medium Cross\")\n",
    "                plt.imshow(mediumCross3, cmap=\"gray\")\n",
    "                plt.figure(3)\n",
    "                plt.title(\"Medium Cross\")\n",
    "                plt.imshow(mediumCross4, cmap=\"gray\")\n",
    "                plt.figure(4)\n",
    "                plt.title(\"Medium Cross\")\n",
    "                plt.imshow(mediumCross5, cmap=\"gray\")\n",
    "                plt.figure(5)\n",
    "                plt.title(\"Medium Cross\")\n",
    "                plt.imshow(mediumCross6, cmap=\"gray\")\n",
    "            case _:\n",
    "                # Anything else.\n",
    "                # \n",
    "                # If `case _:` is omitted, an error will be thrown\n",
    "                # if `something` doesn't match any of the patterns.\n",
    "                raise SystemExit(\"Invalid Input\")\n",
    "        \n",
    "    case _:\n",
    "        # Anything else.\n",
    "        # \n",
    "        # If `case _:` is omitted, an error will be thrown\n",
    "        # if `something` doesn't match any of the patterns.\n",
    "        raise SystemExit(\"Invalid Input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we display the templates, and the chosen target image with the corresponding bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# Bounding Box\n",
    "cv2.rectangle(musicVisualize, (searchBoxX, searchBoxY), (searchBoxX+searchBoxWidth, searchBoxY+searchBoxHeight), colorBox, 2)\n",
    "\n",
    "plt.figure(11,figsize=(15, 15))\n",
    "plt.title(\"Templates\")\n",
    "plt.imshow(musicVisualizeTemplate,cmap=\"gray\")\n",
    "\n",
    "plt.figure(12,figsize=(15, 15))\n",
    "plt.title(\"Bounding Box\")\n",
    "plt.imshow(musicVisualize,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# First format the templates into a list of tuples (label, templateImage)\n",
    "match ruleSet:\n",
    "    case 1:\n",
    "        # Punkte\n",
    "        match templateSet:\n",
    "            case 1:\n",
    "                listTemplate = [('MWD', mediumWhiteDot), ('MBD', mediumBlackDot), ('WDD',mediumWhiteDoubleStrikeDot), ('WSD',mediumWhiteSingleStrikeDot), ('BDD',mediumBlackDoubleStrikeDot), ('BSD',mediumBlackSingleStrikeDot)]\n",
    "         \n",
    "                #listTemplate = [('BWD', bigWhiteDot), ('SWD', smallWhiteDot), ('BBD', bigBlackDot), ('SBD', smallBlackDot), ('MWD', mediumWhiteDot), ('MBD', mediumBlackDot),\n",
    "                #               ('WDD', mediumWhiteDoubleStrikeDot), ('WSD', mediumWhiteSingleStrikeDot), ('BDD', mediumBlackDoubleStrikeDot), ('BSD', mediumBlackSingleStrikeDot)]\n",
    "    \n",
    "            case 2:\n",
    "                listTemplate = [('MWD', mediumWhiteDot), ('MBD', mediumBlackDot), ('WDD',mediumWhiteDoubleStrikeDot), ('WSD',mediumWhiteSingleStrikeDot), ('BDD',mediumBlackDoubleStrikeDot), ('BSD',mediumBlackSingleStrikeDot)]\n",
    "\n",
    "\n",
    "            case _:\n",
    "                # Anything else.\n",
    "                # \n",
    "                # If `case _:` is omitted, an error will be thrown\n",
    "                # if `something` doesn't match any of the patterns.\n",
    "                raise SystemExit(\"Invalid Input\")                            \n",
    "    case 2:\n",
    "        # Pizzicati\n",
    "        match templateSet:\n",
    "            case 1:\n",
    "                listTemplate = [('MC', mediumCross),]\n",
    "            case 2:\n",
    "                # listTemplate = [('MC1', mediumCross),('MC2', mediumCross2),('MC3', mediumCross3),('MC4', mediumCross4),('MC5', mediumCross5),('MC6', mediumCross6),]\n",
    "                listTemplate = [('MC2', mediumCross2),('MC6', mediumCross6),]\n",
    "\n",
    "            case _:\n",
    "                # Anything else.\n",
    "                # \n",
    "                # If `case _:` is omitted, an error will be thrown\n",
    "                # if `something` doesn't match any of the patterns.\n",
    "                raise SystemExit(\"Invalid Input\")\n",
    "\n",
    "    case _:\n",
    "        # Anything else.\n",
    "        # \n",
    "        # If `case _:` is omitted, an error will be thrown\n",
    "        # if `something` doesn't match any of the patterns.\n",
    "        raise SystemExit(\"Invalid Input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate an augmented template list. This means that on top of the original templates we produce scaled versions between 50% and 150%, 90 degree rotations, and mirroring on X and Y axis (and both).\n",
    "\n",
    "For every template in the original list we build 176 templates in total. This is needed as we can potentially present the score in any orientation, and when using a different image we can have a different scaling (e.g. the distance of the image from the lens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "image_maxwh = musicSearch.shape\n",
    "listTemplateSnapshot = listTemplate.copy()\n",
    "listTemplate.clear()\n",
    "for element in listTemplateSnapshot:\n",
    "    for angles in range(0, 360, 90):\n",
    "        for scales in range(50, 160, 10):\n",
    "            # Scale and Rotate\n",
    "            rotated = rotate(element[1], angle=angles)\n",
    "            scaled, percentage = scale_image(rotated, scales, image_maxwh)\n",
    "            listTemplate.append(('S '+str(angles)+' '+str(scales)+' '+element[0], scaled))\n",
    "            listTemplate.append(('U '+str(angles)+' '+str(scales)+' '+element[0], np.flipud(scaled)))\n",
    "            listTemplate.append(('L '+str(angles)+' '+str(scales)+' '+element[0], np.fliplr(scaled)))\n",
    "            listTemplate.append(('UL '+str(angles)+' '+str(scales)+' '+element[0], np.flipud(np.fliplr(scaled))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# Then call the function matchTemplates setting the search box to fall inside the square\n",
    "\n",
    "# Convert musicSearch (RGB) to grayscale (black and white) if it's not already in that format.\n",
    "# If musicSearch has 3 channels then convert, otherwise assume it is already grayscale\n",
    "if len(musicSearch.shape) == 3 and musicSearch.shape[2] == 3:\n",
    "    musicBW = cv2.cvtColor(musicSearch, cv2.COLOR_RGB2GRAY)\n",
    "else:\n",
    "    musicBW = musicSearch.copy()\n",
    "\n",
    "# Using BW Image 0.4 threshold works better, but with the original image you get too many false positives. 0.60 is more likely to work. A lower value requires longer processing time.\n",
    "score_threshold = 0.40\n",
    "\n",
    "listHits = matchTemplates(listTemplate, musicBW, score_threshold=score_threshold,method=cv2.TM_CCOEFF_NORMED, maxOverlap=(0 if ruleSet==1 else 0.1), searchBox=(searchBoxX,searchBoxY, searchBoxWidth, searchBoxHeight))\n",
    "\n",
    "print(\"Found {} hits\".format(len(listHits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# Set the initial threshold and adjustment step\n",
    "local_threshold = score_threshold\n",
    "threshold_step = 0.005\n",
    "\n",
    "# Create a fullscreen window\n",
    "cv2.namedWindow(\"Overlay\", cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty(\"Overlay\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "cv2.startWindowThread()\n",
    "\n",
    "while True:\n",
    "    # Filter listHits based on its third column being >= local_threshold\n",
    "    filtered_listHits = [hit for hit in listHits if hit[2] >= local_threshold]\n",
    "\n",
    "    # Generate the overlay image with the filtered hits\n",
    "    Overlay = drawBoxesOnRGB(\n",
    "        musicVisualize, filtered_listHits,\n",
    "        boxThickness=1, boxColor=[255, 0, 0],\n",
    "        showLabel=True, labelColor=(255, 0, 0), labelScale=0.3\n",
    "    )\n",
    "\n",
    "    # Overlay the current threshold value and instructions in bright green\n",
    "    instructions = f\"Threshold: {local_threshold:.3f}   [Q: increase, A: decrease]   [SPACE/ENTER: confirm]\"\n",
    "    cv2.putText(Overlay, instructions, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Convert the image from RGB to BGR for proper display with OpenCV\n",
    "    Overlay_BGR = cv2.cvtColor(Overlay, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Get the dimensions of the fullscreen window\n",
    "    screen_width, screen_height = get_screen_dimensions(\"Overlay\")\n",
    "\n",
    "    # Calculate the aspect ratios\n",
    "    img_height, img_width = Overlay_BGR.shape[:2]\n",
    "    image_aspect = img_width / img_height\n",
    "    screen_aspect = screen_width / screen_height\n",
    "\n",
    "    # Determine new dimensions to fit screen while preserving aspect ratio\n",
    "    if screen_aspect > image_aspect:\n",
    "        new_height = screen_height\n",
    "        new_width = int(new_height * image_aspect)\n",
    "    else:\n",
    "        new_width = screen_width\n",
    "        new_height = int(new_width / image_aspect)\n",
    "\n",
    "    # Resize the image to these new dimensions\n",
    "    preview_resized = cv2.resize(Overlay_BGR, (new_width, new_height))\n",
    "\n",
    "    # Create a black canvas of screen dimensions and center the resized image within it\n",
    "    canvas = np.zeros((screen_height, screen_width, 3), dtype=np.uint8)\n",
    "    y_offset = (screen_height - new_height) // 2\n",
    "    x_offset = (screen_width - new_width) // 2\n",
    "    canvas[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = preview_resized\n",
    "\n",
    "    # Display the canvas in the fullscreen window\n",
    "    cv2.imshow(\"Overlay\", canvas)\n",
    "\n",
    "    key = cv2.waitKey(0)\n",
    "    if key == ord('q'):\n",
    "        local_threshold = min(1.0, local_threshold + threshold_step)  # Increase threshold but cap to 1.0\n",
    "    elif key == ord('a'):\n",
    "        local_threshold = max(score_threshold, local_threshold - threshold_step)  # Decrease threshold but not below score_threshold\n",
    "    elif key in [32, 13]:  # SPACE or ENTER confirms the selection\n",
    "        break\n",
    "\n",
    "#cv2.destroyWindow(\"Overlay\")\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# Prepare the lists of symbols sorted for the 4 parts\n",
    "listSymbolsLeft=sorted(filtered_listHits, key=lambda tup: (tup[1][0],tup[1][1]) )\n",
    "listSymbolsRight=sorted(filtered_listHits, key=lambda tup: (tup[1][0],tup[1][1]),reverse=True )\n",
    "listSymbolsTop=sorted(filtered_listHits, key=lambda tup: (tup[1][1],tup[1][0]) )\n",
    "listSymbolsBottom=sorted(filtered_listHits, key=lambda tup: (tup[1][1],tup[1][0]),reverse=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# Duration of the piece in seconds (1 to have it normalized between 0 and 1)\n",
    "duration=1\n",
    "# 1 Pixel duration in Seconds\n",
    "onePixelDurLR=duration/searchBoxWidth\n",
    "onePixelDurTB=duration/searchBoxHeight\n",
    "\n",
    "# 1 Pixel in \"MIDI Pitches\"\n",
    "pitchRange=127\n",
    "onePixelPitchLR=pitchRange/searchBoxHeight\n",
    "onePixelPitchTB=pitchRange/searchBoxWidth\n",
    "MIDIFull=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# Part 1 (Left to Right X: Time Y: Pitch)\n",
    "# First we rescale both Axis\n",
    "MIDILeft=[]\n",
    "for x in range (len(listSymbolsLeft)):\n",
    "    listCoords=list(listSymbolsLeft[x][1]).copy()\n",
    "    # 10 Decimals for time\n",
    "    listCoords[0]=round((listSymbolsLeft[x][1][0]-searchBoxX)*onePixelDurLR,10)\n",
    "    # Nearest Integer for MIDI Pitch\n",
    "    listCoords[1]=round(((searchBoxHeight+searchBoxY-listSymbolsLeft[x][1][1])*onePixelPitchLR))\n",
    "    MIDILeft.append((listSymbolsLeft[x][0],(listCoords),listSymbolsLeft[x][2]))\n",
    "MIDIFull.append(MIDILeft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# Part 2 (Right to Left X: Time Y: Pitch)\n",
    "# First we rescale both Axis\n",
    "MIDIRight=[]\n",
    "for x in range (len(listSymbolsRight)):\n",
    "    listCoords=list(listSymbolsRight[x][1]).copy()\n",
    "    # 10 Decimals for time\n",
    "    listCoords[0]=round(duration-((listSymbolsRight[x][1][0]-searchBoxX)*onePixelDurLR),10)\n",
    "    # Nearest Integer for MIDI Pitch\n",
    "    listCoords[1]=round(((searchBoxHeight+searchBoxY-listSymbolsRight[x][1][1])*onePixelPitchLR))\n",
    "    MIDIRight.append((listSymbolsRight[x][0],(listCoords),listSymbolsRight[x][2]))\n",
    "MIDIFull.append(MIDIRight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# Part 3 (Top to Bottom X: Pitch Y: Time)\n",
    "# First we rescale both Axis\n",
    "MIDITop=[]\n",
    "for x in range (len(listSymbolsTop)):\n",
    "    listCoords=list(listSymbolsTop[x][1]).copy()\n",
    "    # 10 Decimals for time\n",
    "    listCoords[0]=round(((listSymbolsTop[x][1][1]-searchBoxY)*onePixelDurTB),10)\n",
    "    # Nearest Integer for MIDI Pitch\n",
    "    listCoords[1]=round(((searchBoxWidth+searchBoxX-listSymbolsTop[x][1][0])*onePixelPitchTB))\n",
    "    MIDITop.append((listSymbolsTop[x][0],(listCoords),listSymbolsTop[x][2]))\n",
    "MIDIFull.append(MIDITop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# Part 4 (Bottom to Top X: Pitch Y: Time)\n",
    "# First we rescale both Axis\n",
    "MIDIBottom=[]\n",
    "for x in range (len(listSymbolsBottom)):\n",
    "    listCoords=list(listSymbolsBottom[x][1]).copy()\n",
    "    # 10 Decimals for time\n",
    "    listCoords[0]=round(duration-((listSymbolsBottom[x][1][1]-searchBoxY)*onePixelDurTB),10)\n",
    "    # Nearest Integer for MIDI Pitch\n",
    "    listCoords[1]=round(((searchBoxWidth+searchBoxX-listSymbolsBottom[x][1][0])*onePixelPitchTB))\n",
    "    MIDIBottom.append((listSymbolsBottom[x][0],(listCoords),listSymbolsBottom[x][2]))\n",
    "MIDIFull.append(MIDIBottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "# Instruments and canonical MIDI range and program number\n",
    "instrumentRange={\n",
    "\"Violin\": (55,103,41, \"Strings\"),\n",
    "\"Viola\": (48,91,42, \"Strings\"),\n",
    "\"Cello\": (36,76,43, \"Strings\"),\n",
    "\"Double Bass\": (28,67,44, \"Strings\"),\n",
    "\"Bass Guitar\": (28,67,34, \"Strings\"),\n",
    "\"Acoustic Guitar\": (40,88,26, \"Strings\"),\n",
    "\"Tuba\": (28,58,59, \"Brass\"),\n",
    "\"Bass Trombone\": (34,67,58, \"Brass\"),\n",
    "\"French Horn\": (34,77,61, \"Brass\"),\n",
    "\"Trombone\": (40,72,58, \"Brass\"),\n",
    "\"Trumpet\": (55,82,57, \"Brass\"),\n",
    "\"Piccolo\": (74,102,73, \"Woodwinds\"),\n",
    "\"Flute\": (60,96,74, \"Woodwinds\"),\n",
    "\"Oboe\": (58,91,69, \"Woodwinds\"),\n",
    "\"Alto Flute\": (55,91,74, \"Other\"),\n",
    "\"English Horn\": (52,81,70, \"Other\"),\n",
    "\"Clarinet\": (50,94,72, \"Woodwinds\"),\n",
    "\"Bass Clarinet\": (38,77,72, \"Woodwinds\"),\n",
    "\"Bassoon\": (34,75,71, \"Woodwinds\"),\n",
    "\"Contrabassoon\": (22,53,71, \"Woodwinds\"),\n",
    "\"Soprano Recorder\": (72,98,75, \"Other\"),\n",
    "\"Alto Recorder\": (65,91,75, \"Other\"),\n",
    "\"Tenor Recorder\": (60,86,75, \"Other\"),\n",
    "\"Bass Recorder\": (53,79,75, \"Other\"),\n",
    "\"Baritone Sax\": (36,69,68, \"Other\"),\n",
    "\"Tenor Sax\": (44,76,67, \"Other\"),\n",
    "\"Alto Sax\": (49,81,66, \"Other\"),\n",
    "\"Soprano Sax\": (56,88,65, \"Other\"),\n",
    "\"Glockenspiel\": (79,108,10, \"Pitched Percussion\"),\n",
    "\"Xylophone\": (65,108,14, \"Pitched Percussion\"),\n",
    "\"Vibraphone\": (53,89,12, \"Pitched Percussion\"),\n",
    "\"Marimba\": (45,96,13, \"Pitched Percussion\"),\n",
    "\"Bass Marimba\": (33,81,13, \"Pitched Percussion\"),\n",
    "\"Celeste\": (60,108,9, \"Pitched Percussion\"),\n",
    "\"Tubular Bells\": (60,77,15, \"Pitched Percussion\"),\n",
    "\"Timpani\": (40,55,48, \"Pitched Percussion\"),\n",
    "\"Harpsichord\": (29,89,7, \"Keyboard\"),\n",
    "\"Harp\": (24,103,47, \"Other\"),\n",
    "\"Piano\": (21,108,1, \"Keyboard\"),\n",
    "\"Unpitched Percussion\": (35,81,10, \"Unpitched Percussion\"),\n",
    "}\n",
    "\n",
    "# Dynamic and average MIDI Velocity\n",
    "dynamicRange={\n",
    "\"ppp\":(16),\n",
    "\"pp\":(32),\n",
    "\"p\":(48),\n",
    "\"mp\":(64),\n",
    "\"mf\":(80),\n",
    "\"f\":(96),\n",
    "\"ff\":(112),\n",
    "\"fff\":(127),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally want to build a MIDI rendering of the score, and a \"transcription\" with MusicXML.\n",
    "\n",
    "One notable situation we need to address is that when we generate a NoteOn we need to generate a corresponding NoteOff somewhere in the future.\n",
    "\n",
    "MIDI Files encode the timing of events as a delta from the previous event.\n",
    "\n",
    "The solution is to build a data structure that contains note off with the absolute timing. Then sort it based on the timing attribute, and finally convert to delta timing by subtracting from the timing of the current event the timing of the previous event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%memit -r 1\n",
    "match scoreNumber:\n",
    "        case 1|2:\n",
    "                MIDIFileName='Punkte'+str(scoreNumber)\n",
    "                noteDuration=32\n",
    "\n",
    "        case 3|4:\n",
    "                MIDIFileName='Pizzicati'+str(scoreNumber)\n",
    "                noteDuration=32\n",
    "\n",
    "        case 5|6:\n",
    "                # File name\n",
    "                while True:\n",
    "                        user_file_name = input(\"Enter the name of the file to save: \")\n",
    "                        if user_file_name.strip():\n",
    "                                MIDIFileName = user_file_name\n",
    "                                break\n",
    "                        else:\n",
    "                                print(\"Filename cannot be empty. Please enter a valid filename.\")\n",
    "\n",
    "                # Individual note duration\n",
    "                while True:\n",
    "                        note_duration_input = input(\"Enter minimum note duration (e.g 64 for 1/64th): \")\n",
    "                        try:\n",
    "                                noteDuration = int(note_duration_input)\n",
    "                                break\n",
    "                        except ValueError:\n",
    "                                print(\"Invalid input. Please enter a valid integer for note duration.\")\n",
    "        case _:\n",
    "        # Anything else.\n",
    "        # \n",
    "        # If `case _:` is omitted, an error will be thrown\n",
    "        # if `something` doesn't match any of the patterns.\n",
    "                raise SystemExit(\"Invalid Input\")  \n",
    "\n",
    "\n",
    "\n",
    "# List to hold conversion tasks (tuples of (input, output))\n",
    "conversion_tasks = []\n",
    "\n",
    "# Tempo in BPM\n",
    "performanceTempo=60\n",
    "# Duration at x BPM in sec\n",
    "while True:\n",
    "    duration_input = input(\"Enter performance duration in seconds: \")\n",
    "    try:\n",
    "        performanceDuration = int(duration_input)\n",
    "        break\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a valid integer for performance duration.\")\n",
    "performanceMins=performanceDuration/60\n",
    "# Ticks per beat (conventionally quarter note)\n",
    "ticksPerBeat=480\n",
    "\n",
    "noteDelta=int(ticksPerBeat/(noteDuration/4))\n",
    "# Compute the number of microseconds per tick (used for setting BPM) as the number of microseconds in 1 minute divided by BPM\n",
    "microsecondsPerTick=int(60000000/performanceTempo)\n",
    "# Conversion from 0-1 Time unit to Ticks\n",
    "conversionTicks=int(ticksPerBeat*performanceTempo*performanceMins)\n",
    "\n",
    "# List of instruments and order of appearance of the \"directions\"\n",
    "instrumentList=['Violin','Trumpet','Flute','Piano']\n",
    "trackOrder=['Left','Right','Top','Bottom']\n",
    "\n",
    "# Create the complete MIDI File\n",
    "midFull = MidiFile(ticks_per_beat=ticksPerBeat, type=1,)\n",
    "for x in range(len(MIDIFull)):\n",
    "        # Generate a new track\n",
    "        track = MidiTrack()\n",
    "        # Add it to the full file AND to a file for individual tracks\n",
    "        midFull.tracks.append(track)\n",
    "        midLocal=MidiFile(ticks_per_beat=ticksPerBeat, type=1,)\n",
    "        midLocal.tracks.append(track)\n",
    "        # Set the BPM in MIDI Track\n",
    "        track.append(MetaMessage('set_tempo', tempo=microsecondsPerTick))\n",
    "        # Set the instrument according to GM 1 (e.g. 46 is Pizzicato Strings)\n",
    "        instrument=instrumentRange[instrumentList[x]]\n",
    "        if instrument[3]=='Unpitched Percussion':\n",
    "                track.append(Message('program_change', program = instrument[2], channel = 10))\n",
    "        else:\n",
    "                track.append(Message('program_change', program = instrument[2], channel = 0))\n",
    "        pitchCorrection=(instrument[1]-instrument[0])/pitchRange\n",
    "        linearizedEvents=[]\n",
    "        for event in MIDIFull[x]:\n",
    "                # Here we need to process individual symbols that can translate to one or more notes\n",
    "                currentPitch=round((event[1][1]*pitchCorrection)+instrument[0])\n",
    "                match ruleSet:\n",
    "                        case 1:\n",
    "                                # In Punkte symbols can generate a sequence of 1 to 3 notes for all instruments, and on top of that can generate chords for piano\n",
    "                                # Punkte also alters the dynamics\n",
    "                                #Parse event[0]\n",
    "                                tokens=event[0].split(\" \")\n",
    "                                # Token[2] gives us the \"size\" of the symbol\n",
    "                                size=int(tokens[2])\n",
    "                                # Token[3] gives us the type of symbol: plain, single or double strike\n",
    "                                symbol=tokens[3]\n",
    "\n",
    "                                clusterNum=1\n",
    "                                if instrument[3]=='Keyboard':\n",
    "                                       # For keyboards size is mapped to note clusters\n",
    "                                       clusterNum=int(((size-50.0)/100.0)*(4-1)+1)\n",
    "                                       # Velocity is mapped to black/white dots\n",
    "                                       match symbol:\n",
    "                                                case 'MWD'|'WSD'|'WDD':\n",
    "                                                        velocity=dynamicRange['pp']\n",
    "                                                case 'MBD'|'BSD'|'BDD':\n",
    "                                                        velocity=dynamicRange['f']\n",
    "                                                case _:\n",
    "                                                        # Anything else.\n",
    "                                                        # \n",
    "                                                        # If `case _:` is omitted, an error will be thrown\n",
    "                                                        # if `something` doesn't match any of the patterns.\n",
    "                                                        raise SystemExit(\"Invalid Input\")\n",
    "                                else:\n",
    "                                # For everything but keyboards size is mapped to dynamics\n",
    "                                        velocity=int(((size-50.0)/100.0)*(dynamicRange['ff']-dynamicRange['pp'])+dynamicRange['pp'])\n",
    "\n",
    "                                match symbol:\n",
    "                                        case 'MWD':\n",
    "                                                repetitions=1\n",
    "                                                if instrument[3]=='Woodwinds':\n",
    "                                                        repetitions=0\n",
    "                                        case 'MBD':\n",
    "                                                repetitions=1\n",
    "                                                if instrument[3]=='Brass':\n",
    "                                                        repetitions=0\n",
    "                                        case 'WSD':\n",
    "                                                repetitions=2\n",
    "                                                if instrument[3]=='Woodwinds':\n",
    "                                                        repetitions=0\n",
    "                                        case 'BSD':\n",
    "                                                repetitions=2\n",
    "                                                if instrument[3]=='Brass':\n",
    "                                                        repetitions=0\n",
    "                                        case 'WDD':\n",
    "                                                repetitions=3\n",
    "                                                if instrument[3]=='Woodwinds':\n",
    "                                                        repetitions=0\n",
    "                                        case 'BDD':\n",
    "                                                repetitions=3\n",
    "                                                if instrument[3]=='Brass':\n",
    "                                                        repetitions=0\n",
    "                                        case _:\n",
    "                                                # Anything else.\n",
    "                                                # \n",
    "                                                # If `case _:` is omitted, an error will be thrown\n",
    "                                                # if `something` doesn't match any of the patterns.\n",
    "                                                raise SystemExit(\"Invalid Input\")\n",
    "                                for t in range(repetitions):\n",
    "                                        for w in range(clusterNum):\n",
    "                                                linearizedEvents.append(('note_on', currentPitch+w, velocity, int((event[1][0]*conversionTicks)+(noteDelta*(t)))))\n",
    "                                                linearizedEvents.append(('note_off', currentPitch+w, 127, int(event[1][0]*conversionTicks)+(noteDelta*(t+1))))\n",
    "                        case 2:\n",
    "                                #Pizzicati\n",
    "                                linearizedEvents.append(('note_on', currentPitch, 100, int(event[1][0]*conversionTicks)))\n",
    "                                linearizedEvents.append(('note_off', currentPitch, 127, int(event[1][0]*conversionTicks)+noteDelta))\n",
    "\n",
    "                        case _:\n",
    "                                # Anything else.\n",
    "                                # \n",
    "                                # If `case _:` is omitted, an error will be thrown\n",
    "                                # if `something` doesn't match any of the patterns.\n",
    "                                raise SystemExit(\"Invalid Input\")  \n",
    "\n",
    "        # Sort in ascending order of delta\n",
    "        linearSortedEvents=sorted(linearizedEvents, key=lambda tup: (tup[3],tup[0]))\n",
    "\n",
    "        for y in range(len(linearSortedEvents)):\n",
    "                # Correct for Delta Time\n",
    "                if (y==0):\n",
    "                        track.append(Message(linearSortedEvents[y][0], note=linearSortedEvents[y][1], velocity=linearSortedEvents[y][2], time=linearSortedEvents[y][3]))\n",
    "                        continue\n",
    "                track.append(Message(linearSortedEvents[y][0], note=linearSortedEvents[y][1], velocity=linearSortedEvents[y][2], time=linearSortedEvents[y][3]-linearSortedEvents[y-1][3]))\n",
    "\n",
    "        output_mid = './output/' + MIDIFileName + '_' + trackOrder[x] + '.mid'\n",
    "        midLocal.save(output_mid)\n",
    "        xml_file = './output/' + MIDIFileName + '_' + trackOrder[x] + '.musicxml'\n",
    "        conversion_tasks.append((output_mid, xml_file))\n",
    "\n",
    "# Save the full MIDI file and add it to conversion tasks\n",
    "full_mid_file = './output/' + MIDIFileName + '_Full.mid'\n",
    "midFull.save(full_mid_file)\n",
    "full_xml_file = './output/' + MIDIFileName + '_Full.musicxml'\n",
    "conversion_tasks.append((full_mid_file, full_xml_file))\n",
    "\n",
    "# Convert all tasks in parallel\n",
    "def convert_to_musicxml(mid_file_path, xml_file_path):\n",
    "    # This function must be pickleable if we want to use ProcessPoolExecutor. Is it?\n",
    "    parsed = music21.converter.parse(mid_file_path, forceSource=True, quarterLengthDivisors=[8])\n",
    "    if parsed.metadata is None:\n",
    "        parsed.metadata = music21.metadata.Metadata()\n",
    "    parsed.metadata.title = 'Ludus Musicalis'\n",
    "    parsed.metadata.composer = 'Roman Haubenstock-Ramati'\n",
    "    parsed.write('musicxml', fp=xml_file_path)\n",
    "    return xml_file_path\n",
    "\n",
    "def parallel_conversion(conversion_tasks):\n",
    "    # Use ThreadPoolExecutor with spawn start method\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(convert_to_musicxml, mid, xml): (mid, xml) \n",
    "                   for mid, xml in conversion_tasks}\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            mid_file, xml_file = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                print(f'Conversion complete: {result}')\n",
    "            except Exception as e:\n",
    "                print(f'Conversion failed for {mid_file} to {xml_file}: {e}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Force the spawn start method in notebooks if not already set.\n",
    "    multiprocessing.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "    parallel_conversion(conversion_tasks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
